# -*- coding: utf-8 -*-
"""NLP_study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/115IfpAqnI0GrlUAP6udFUomEbfe3yles

# 0.Importing libraries
"""

import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import tensorflow
import keras
import gensim
import warnings
warnings.filterwarnings('ignore')

#nltk.download()

!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash

!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git

cd Mecab-ko-for-Google-Colab

!bash install_mecab-ko_on_colab_light_220429.sh

from konlpy.tag import Okt, Mecab

"""# 1.Warming up - Pandas & Numpy

##Pandas - Series
"""

sr = pd.Series([100, 200], index = ["pizza", "chicken"])
print("Print the Series :")
print('-' * 20)
print(sr)

print("Values of the series {}:" .format(sr.values))
print("Indices of the series {}:" .format(sr.index))

"""##Pandas - DataFrame"""

values = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
index = ['one', 'two', 'three']
columns = ['A', 'B', 'C']

df = pd.DataFrame(values, index = index, columns = columns)

print("Print the DataFrame : ")
print('-' * 20)
print(df)

print(df.values)
print(df.index)
print(df.columns)

df['A']

df.iloc[0]

"""##Numpy - array"""

vec = np.array(np.arange(1, 6))
mat = np.array([[10, 20, 30], [ 60, 70, 80]])

print(mat)

print(vec.ndim)
print(vec.shape)

print(mat.ndim)
print(mat.shape)

zero_mat = np.zeros((2, 3))
print(zero_mat)

one_mat = np.ones((2, 3))
print(one_mat)

same_value_mat = np.full((2, 3), 5)
print(same_value_mat)

eye_mat = np.eye(5)
print(eye_mat)

random_mat = np.random.random((2, 3))
print(random_mat)

reshape_mat = np.array(np.arange(30)).reshape((5, 6))
print(reshape_mat)

slicing_mat = reshape_mat[0, :]
print(slicing_mat)

indexing_mat = reshape_mat[[0, 1], [1, 2]]
print(indexing_mat)

mat1 = np.arange(1, 5).reshape((2, 2))
mat2 = np.arange(5, 9).reshape((2, 2))
mat3 = np.dot(mat1, mat2)
print(mat3)

"""##Matplotlib"""

plt.title('test')
plt.plot([1, 2, 3, 4], [2, 4, 8, 6])
plt.show()

plt.title('test')
plt.plot([1, 2, 3, 4], [2, 4, 8, 6])
plt.xlabel('hours')
plt.ylabel('score')
plt.show()

plt.title('test')
plt.plot([1, 2, 3, 4], [2, 4, 8, 6])
plt.plot([1.5, 2.5, 3.5, 4.5], [3, 5, 8, 10])
plt.xlabel('hours')
plt.ylabel('score')
plt.legend(['A student', 'B student'])
plt.show()

"""# 2.Text preprocessing

##2-1.Tokenization

Terminology
*    Corpus: Natural Language Data
*    Tokenization: Deviding Data into units called "Token"
*    Token: Base unit for tokenization which can be from a charactor to words

Required Libraries or Installs for this chapter
1. For word tokenization
*    from nltk.tokenize import word_tokenize, WordPunctTokenizer
*    from tensorflow.keras.preprocessing.text import text_to_word_sequence
*    from nltk.tokenize import TreebankWordTokenizer
2. For sentence tokenization
*    from nltk.tokenize import sent_tokenize
3. For Korean sentence tokenization
*    pip install kss
*    import kss
4. For Part-Of-Speech tagging
*    from nltk.tag import pos_tag
5. For overall Korean NLP preprocessing
*    from konlpy.tag import Okt
*    from konlpy.tag import Kkma

###Word Tokenization
We can't simply tokenize one or more sentences because there are punctuations and symbols.

 And someitmes they have meaning but somtimes they don't.
"""

#Three ways for word tokenization
from nltk.tokenize import word_tokenize, WordPunctTokenizer
from tensorflow.keras.preprocessing.text import text_to_word_sequence

#You will need this cell to prevent an error
nltk.download('punkt')

"""Example for dealing with apostrophe"""

text = "Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pasty shop."

print('Tokenize word1 : ',
      word_tokenize(text))

"""word_tokenize's result
* Don't -> Do, n't
* Jone's -> Jone, 's
"""

print('Tokenize word2 : ',
      WordPunctTokenizer().tokenize(text))

"""WordPunctTokenizer's result
* Don't -> Don, ', t
* Jone's -> Jone, ', s
"""

print('Tokenize word3 : ',
      text_to_word_sequence(text))

"""text_to_word_sequence's result
* Don't -> don't
* Jone's -> jone's

On the other hand, Tokenization is not simply about separating words.

Since we will face hyphenated words and even punctuations, and we need meaning from them, sometimes we should keep them.
"""

from nltk.tokenize import TreebankWordTokenizer

tokenizer = TreebankWordTokenizer()

text = "Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own."

print("Treebank word tokenizer : ", tokenizer.tokenize(text))

"""TreebankWordTokenizer's result
* home-bird -> home-bird
* doesn't -> does, n't

So, now we can conclude that every function has its own rules.

And we should be capable of choosing the best one for the purpose.

###Sentence Tokenization
Sometimes, punctuations don't work as its sentence's boundary.

Let's check if our nltk's sent_tokenizer recognize boundary one.
"""

from nltk.tokenize import sent_tokenize

text = "His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near."

print("Sentence tokenization1 : ", sent_tokenize(text))

"""It seems it works pretty well.

Let's check with other corpus.
"""

text = "I am actively looking for Ph.D. students. and you are a Ph.D student."
print("Sentence tokenization2 : ", sent_tokenize(text))

"""In the text, there is 'Ph.D' where the dot is not boundary.

Still it separated sentences perfectly!

This time, let's look at the sentence tokenizer for Korean Language
"""

!pip install kss

import kss

text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'

print('Korean sentence tokenization : ', kss.split_sentences(text))

"""It works well! The example sentences make me a little scared though...

###POS tagging
Since Korean language is agglutinative language and has difficult rules for spacing, we need to analyse POS, Part-Of-Speech.

You can do the POS tagging with nltk.tag's pos_tag function.
"""

from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag
nltk.download('averaged_perceptron_tagger')

text = "I am actively looking for Ph.D. students. and you are a Ph.D. student."
tokenized_sentence = word_tokenize(text)

print('Word tokenization :', tokenized_sentence)
print('POS tagging : ',pos_tag(tokenized_sentence))

"""For Korean language, you can use konlpy.tag's Okt or Kkma"""

from konlpy.tag import Okt
from konlpy.tag import Kkma

okt = Okt()
kkma = Kkma()

print("OKT morpheme analysis : ", okt.morphs("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))
print("OKT POS tagging : ", okt.pos("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))
print("OKT extracting Noun : ", okt.nouns("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))

print('꼬꼬마 morpheme analysis : ', kkma.morphs("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))
print('꼬꼬마 POS tagging : ', kkma.pos("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))
print('꼬꼬마 extracting Noun : ', kkma.nouns("열심히 코딩한 당신, 연휴에는 여행을 가봐요"))

"""###Sum up
* We need to preprocess corpus and one of its step is tokenization.
* Tokenization depends on the characteristics of the language and the purpose.
* You need to be able to choose the best way to preserve as much imformation as possible for your goal

##2-2.Cleaning and Normalization

Terminology
* Cleaning: Getting rid of noise from corpus
* Normalization: Converting different words with the same meaning into the same word

We conduct cleaning and normalization before or after tokenization.

The goal is to eliminate noise and stopwords which are not meaningful for the purpose.

The next cell shows an example of dealing with corpus using Regular Expression.
"""

import re
text = "I was wondering if anyone out there could enlighten me on this car."
shortword = re.compile(r'\w*\b\w{1,2}\b')
print(shortword.sub('', text))

"""As we can see in the cell above, we can delete words that are too short using Regular Expression.

##2-3.Stemming and Lemmatization

Terminology
* Stemming: extracting stem from a word
* Stem: a part of the word that has essential meaning
* Affix: a part of the word that has additional meaning
* Lemma: dictionary form of the word

In this part, we ara going to look into stemming and lemmatization.

Those are used for normalization.

1. Lemmatization
"""

from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()

words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']

print('Before lemmatization : ', words)
print('After lemmatization : ',[lemmatizer.lemmatize(word) for word in words])

lemmatizer.lemmatize('dies', 'v')

lemmatizer.lemmatize('watched', 'v')

lemmatizer.lemmatize('has', 'v')

"""2. Stemming

Stemming is not a sophisticated process.

Because its approach is based on simple rules.
"""

from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
nltk.download('punkt')

stemmer = PorterStemmer()

sentence = "This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes."
tokenized_sentence = word_tokenize(sentence)

print("Before stemming : ", tokenized_sentence)
print("After stemming : ", [stemmer.stem(word) for word in tokenized_sentence])

words = ['formalize', 'allowance', 'electricical']

print("Before stemming : ", words)
print("After stemming : ", [stemmer.stem(word) for word in words])

"""It's not working correctly because it simply follows the rules."""

from nltk.stem import PorterStemmer
from nltk.stem import LancasterStemmer

porter_stemmer = PorterStemmer()
lancaster_stemmer = LancasterStemmer()

words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']
print("Before stemming : ", words)
print("After Porter Stemming : ", [porter_stemmer.stem(word) for word in words])
print("After Lancaster Stemming : ", [lancaster_stemmer.stem(word) for word in words])

"""Each stemmer has its own pros and cones.

So we should decide which one to employ based on the situation we are facing.

And we can apply lemmatization and stemming to korean corpus.

But make sure you are considering Korean grammer rules and your goal.

##2-4.Stopword

Stopwords are words that frequently appear but are not meaningful for the NLP analysis.
"""

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from konlpy.tag import Okt

"""We can import preset stopword list."""

nltk.download('stopwords')
stop_words_list = stopwords.words('english')
print('Number of stopword : ', len(stop_words_list))
print('Print 10 stopwords : ', stop_words_list[:10])

"""And also delete stopwards from your corpus with it."""

example = "Family is not an important thing. It's everything."
stop_words = set(stopwords.words('english'))
word_tokens = word_tokenize(example)
result = []
for word in word_tokens:
  if word not in stop_words:
    result.append(word)
print("Before eliminating stopword : ",word_tokens)
print("After eliminating stopword : ", result)

"""Like the following example, you can make a set of stopwords and eliminate them from your corpus."""

#Korean
okt = Okt()

example = "고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지."
stop_words = "를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는"

stop_words = set(stop_words.split(' '))
word_tokens = okt.morphs(example)

result = [word for word in word_tokens if not word in stop_words]

print('Before eliminating stopword : ', word_tokens)
print('After eliminating stopword : ', result)

"""##2-5.Regular Expression

I will skip this part...

Regular Expression is useful for cleaning and normalization.

But you should learn it by yourself.
"""

import re

r = re.compile("a.c")
r.search("kkk")

r.search("abc")

r = re.compile("ab?c")
r.search("abbc")

r.search("abc")

r.search("ac")

r = re.compile("ab*c")
r.search("a")

r.search("ac")

r.search("abc")

r.search("abbbc")

r = re.compile("ab+c")
r.search("ac")

r.search("abc")

r.search("abbbbc")

r = re.compile("^ab")
r.search("bbc")
r.search("zab")

r.search("abz")

r = re.compile("ab{2}c")
r.search("ac")
r.search("abc")
r.search("abbbbc")

r.search("abbc")

r = re.compile("ab{2,8}c")
r.search("ac")
r.search("abc")
r.search("abbbbbbbbbc")

r.search("abbc")

r.search("abbbbbbbbc")

r = re.compile("a{2,}bc")
r.search("bc")
r.search("aa")

r.search("aabc")

r.search("aaaaaaaabc")

r = re.compile("[abc]") #[abc] equals to [a-c]
r.search("zzzz")

r.search("a")

r.search("aaaa")

r.search("zbaac")

r = re.compile("[a-z]")
r.search("AAA")
r.search("111")

r.search("aBC")

r = re.compile("[^abc]")
r.search("a")
r.search("ab")
r.search("b")

r.search("d")

r.search("1")

r = re.compile("ab.")
r.match("kkkabc")

r.match("abckkk")

text = "사과 딸기 수박 메론 바나나"
re.split(" ", text)

text = """사과
딸기
수박
메론
바나나"""

re.split("\n", text)

text = "사과+딸기+수박+메론+바나나"

re.split("\+", text)

text = """이름 : 김철수
전화번호 : 010 - 1234 - 1234
나이 : 30
성별 : 남"""

re.findall("\d+", text)

re.findall("\d+", "문자열입니다.")

text = "Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern."

preprocessed_text = re.sub('[^a-zA-Z]', ' ', text)
print(preprocessed_text)

text = """100 John    PROF
101 James   STUD
102 Mac   STUD"""

re.split('\s+', text)

re.findall('\d+', text)

re.findall('[A-Z]', text)

re.findall('[A-Z]{4}', text)

re.findall('[A-Z][a-z]+', text)

from nltk.tokenize import RegexpTokenizer

text = "Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop"

tokenizer1 = RegexpTokenizer("[\w]+")
tokenizer2 = RegexpTokenizer("\s+", gaps = True)

print(tokenizer1.tokenize(text))
print(tokenizer2.tokenize(text))

"""##2-6.Integer Encoding

Computers can calculate numbers better than characters.

So in this part, we are going to map tokenized words to integers for the better computing.

###1)Integer Encoding

We can assign a number based on the word's frequency rank in the corpus.

Here's an example.
"""

from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

raw_text = "A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain."

nltk.download('punkt')
sentences = sent_tokenize(raw_text)
print(sentences)

nltk.download('stopwords')
vocab = {}
preprocessed_sentences = []
stop_words = set(stopwords.words('english'))

for sentence in sentences:
  tokenized_sentence = word_tokenize(sentence)
  result = []

  for word in tokenized_sentence:
    word = word.lower()

    if word not in stop_words:

      if len(word) > 2:
        result.append(word)

        if word not in vocab:
          vocab[word] = 0
        vocab[word] += 1
  preprocessed_sentences.append(result)
print(preprocessed_sentences)

"""Tokenization, cleaning, normalization and counting.

For counting, you can view the importance of normalization.
"""

print("Word set :", vocab)

print(vocab["barber"])

"""And you can sort the dictionary in descending order."""

vocab_sorted = sorted(vocab.items(), key = lambda x : x[1], reverse = True)
print(vocab_sorted)

"""Assigning numebrs by order."""

word_to_index = {}
i = 0
for (word, frequency) in vocab_sorted:
  if frequency > 1:
    i = i + 1
    word_to_index[word] = i
print(word_to_index)

"""You can choose how many tokens you are going to use by the frequency ranking."""

vocab_size = 5

words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]

for w in words_frequency:
  del word_to_index[w]
print(word_to_index)

"""If you decide the rank, the problem now is that there must be some tokens that are out of vocabulary; we call them OOV."""

word_to_index['OOV'] = len(word_to_index) + 1
print(word_to_index)

"""So the following cell shows how to treat OOV; it assigned them a new number."""

encoded_sentences = []
for sentence in preprocessed_sentences:
  encoded_sentence = []
  for word in sentence:
    try:
      encoded_sentence.append(word_to_index[word])
    except KeyError:
      encoded_sentence.append(word_to_index['OOV'])
  encoded_sentences.append(encoded_sentence)
print(encoded_sentences)

"""###2)Using Counter

Actually, we have simpler method.

Let's check it out!
"""

from collections import Counter

print(preprocessed_sentences)

#words = np.hstack(preprocessed_sentences)
all_words_list = sum(preprocessed_sentences, [])
print(all_words_list)

vocab = Counter(all_words_list)
print(vocab)

print(vocab["barber"])

vocab_size = 5
vocab = vocab.most_common(vocab_size)
vocab

"""As you see, Counter method automatically counts the number of same tokens."""

word_to_index = {}
i = 0
for (word, frequency) in vocab:
  i = i + 1
  word_to_index[word] = i
print(word_to_index)

"""###3)Using FreqDist of NLTK

And just like Counter, we have another method.
"""

from nltk import FreqDist
import numpy as np

vocab = FcreqDist(np.hstack(preprocessed_sentenes))

print(vocab["barber"])

vocab_size = 5
vocab = vocab.most_common(vocab_size)
print(vocab)

word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}
print(word_to_index)

"""**Understanding enumerate**

Just like the cell above, we can use enumerate.

It returns input's value and its key.
"""

test_input = ['a', 'b', 'c', 'd', 'e']
for index, value in enumerate(test_input):
  print("value : {}, index : {}".format(value, index))

"""###Text preprocessing with Keras

A whole workflow so far with keras
"""

from tensorflow.keras.preprocessing.text import Tokenizer

preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]

tokenizer = Tokenizer()

tokenizer.fit_on_texts(preprocessed_sentences)

print(tokenizer.word_index)

print(tokenizer.word_counts)

print(tokenizer.texts_to_sequences(preprocessed_sentences))

vocab_size = 5
tokenizer = Tokenizer(num_words = vocab_size + 1)
tokenizer.fit_on_texts(preprocessed_sentences)

print(tokenizer.word_index)

print(tokenizer.word_counts)

print(tokenizer.texts_to_sequences(preprocessed_sentences))

tokenizer = Tokenizer()
tokenizer.fit_on_texts(preprocessed_sentences)

"""Here's another example of the whole precess so far.

This example is different because it assigns 1 on OOV.
"""

vocab_size = 5
words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1]

for word in words_frequency:
  del tokenizer.word_index[word]
  del tokenizer.word_counts[word]

print(tokenizer.word_index)
print(tokenizer.word_counts)
print(tokenizer.texts_to_sequences(preprocessed_sentences))

voacb_size = 5
tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')
tokenizer.fit_on_texts(preprocessed_sentences)

print('Number of OOV\'s index : {}'.format(tokenizer.word_index['OOV']))

print(tokenizer.texts_to_sequences(preprocessed_sentences))

"""##2-7.Padding

After tokenization, if the length of the sentence or the passage,

 you can switch the tokens into vectors comprised of numbers

 so that you can improve the speed of calculation.

###1.Padding with Numpy
"""

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer

preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]

tokenizer = Tokenizer()
tokenizer.fit_on_texts(preprocessed_sentences)
encoded = tokenizer.texts_to_sequences(preprocessed_sentences)
print(encoded)

max_len = max(len(item) for item in encoded)
print("Max length :", max_len)

for sentence in encoded:
  while len(sentence) < max_len:
    sentence.append(0)
padded_np = np.array(encoded)
padded_np

"""As you see, we appended 0s after all the existing elements.

###2.Padding with Keras preprocessing
"""

from tensorflow.keras.preprocessing.sequence import pad_sequences

encoded = tokenizer.texts_to_sequences(preprocessed_sentences)
print(encoded)

padded = pad_sequences(encoded)
padded

"""However, in Keras, you can put 0s before the existing elements."""

padded = pad_sequences(encoded, padding = 'post')
padded

"""Of course you can put 0s after them."""

(padded == padded_np).all()

"""And with Keras, you can set the maximum length."""

padded = pad_sequences(encoded, padding = 'post', maxlen = 5)
padded

padded = pad_sequences(encoded, padding = 'post', truncating = 'post', maxlen = 5)
padded

"""We can set the dummy number as whatever we want instead of 0."""

last_value = len(tokenizer.word_index) + 1
print(last_value)

padded = pad_sequences(encoded, padding = 'post', value = last_value)
padded

"""##2-8.One-Hot Encoding

One-Hot Encoding is a good way to improve your computer's calculation speed.

In One-Hot Encoding, each column represents a certain token.

And each row has the only one 1 value which represents which token the row was.

But it has side effect in which we need more memory.

Let's look into the following example.

###with konlpy
"""

from konlpy.tag import Okt

okt = Okt()
tokens = okt.morphs("나는 자연어 처리를 배운다")
print(tokens)

word_to_index = {word : index for index, word in enumerate(tokens)}
print("Word set :", word_to_index)

"""Here, we define a function and put the only 1 in the row."""

def one_hot_encoding(word, word_to_index):
  one_hot_vector = [0] * (len(word_to_index))
  index = word_to_index[word]
  one_hot_vector[index] = 1
  return one_hot_vector

one_hot_encoding("자연어", word_to_index)

"""###with Keras"""

text = "나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야"

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical

text = "나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야"

tokenizer = Tokenizer()
tokenizer.fit_on_texts([text])
print("Word set :", tokenizer.word_index)

sub_text = "점심 먹으러 갈래 메뉴는 햄버거 최고야"
encoded = tokenizer.texts_to_sequences([sub_text])[0]
print(encoded)

"""Keras is rather simpler than the previous way."""

one_hot = to_categorical(encoded)
print(one_hot)

"""##2-9.Splitting Data

To improve your model's accuracy, you will need to split your data set.

It's called splitting.

Normally, when we are splitting data set, we split it into 3 sets.

Train set, validation set, test set.

You train your model with train set and use the validation set to prevent your model from overfitting.

For the last step, you will use test set to evaluate your model.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

"""###1.Splitting into X and y from the original data

Zip function
"""

#with zip function
X, y = zip(['a', 1], ['b', 2], ['c', 3])
print("X data :", X)
print("y data :", y)

sequences = [['a', 1], ['b', 2], ['c', 3]]
X, y = zip(*sequences)
print("X data :", X)
print("y data :", y)

"""With DataFrame"""

#with DataFrame

values = [['당신에게 드리는 마지막 혜택!', 1],
['내일 뵐 수 있을지 확인 부탁드...', 0],
['도연씨. 잘 지내시죠? 오랜만입...', 0],
['(광고) AI로 주가를 예측할 수 있다!', 1]]
columns = ['메일 본문', '스팸 메일 유무']

df = pd.DataFrame(values, columns = columns)
df

X = df['메일 본문']
y = df['스팸 메일 유무']

print("X data :", X.to_list())
print("y data :", y.to_list())

"""With Numpy"""

#with Numpy
np_array = np.arange(0, 16).reshape((4, 4))
print("Whole data :")
print(np_array)

X = np_array[:, :3]
y = np_array[:, 3]

print("X data :")
print(X)
print("y data :", y)

"""###2.Extracting test data

With sklearn
"""

#with scikit-learn

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)

X, y = np.arange(10).reshape((5, 2)), range(5)

print("Whole X data :")
print(X)
print("Whole y data :")
print(list(y))

"""All you need to do is using the train_test_split function."""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1234)

print("X train data :")
print(X_train)
print("X test data :")
print(X_test)

print("y train data :")
print(y_train)
print("y test data :")
print(y_test)

"""You can set different random_state value."""

#different value for random_state

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)

print("y train data :")
print(y_train)
print("y test data :")
print(y_test)

# back to 1234 for random_state value
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)

print('y 훈련 데이터 :')
print(y_train)
print('y 테스트 데이터 :')
print(y_test)

"""You can also manually split your data."""

#manual extracting from here
X, y = np.arange(0, 24).reshape((12, 2)), range(12)

print("Whole X data :")
print(X)
print("Whole y data :")
print(list(y))

"""\*Warning!

you should substract the number for train set length from the whole length

If you set the number of test set length by multiplying 0.2, there must be an omission

because in python it will automatically switch floating point number to the integer type
"""

num_of_train = int(len(X) * 0.8)
num_of_test = int(len(X) - num_of_train)
print("Size of train data :", num_of_train)
print("Size of test data :", num_of_test)

X_test = X[num_of_train:]
y_test = y[num_of_train:]
X_train = X[:num_of_train]
y_train = y[:num_of_train]

print("X test data :")
print(X_test)
print("y test data :")
print(list(y_test))

"""##2-10.Text Preprocessing Tools for Korean Text

###1.PyKoSpacing

This package is for correcting inappropriately spaced sentences.
"""

pip install git+https://github.com/haven-jeon/PyKoSpacing.git

sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'

new_sent = sent.replace(" ", "")
print(new_sent)

from pykospacing import Spacing
spacing = Spacing()
kospacing_sent = spacing(new_sent)

print(sent)
print(kospacing_sent)

"""###2.Py-Hanspell

*   Skip running the following cells
*   Because currently Py-hanspell doesn't work. (03/03/2024)

This one is for grammar check and spacing.




"""

#pip install git+https://github.com/ssut/py-hanspell.git

#from hanspell import spell_checker

#sent = "맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 "
#spelled_sent = spell_checker.check(sent)

#hanspell_sent = spelled_sent.checked
#print(hanspell_sent)

#spelled_sent = spell_checker.check(new_sent)

#hanspell_sent = spelled_sent.checked
#print(hanspell_sent)
#print(kospacing_sent)

"""###3.Tokenization with SOYNLP

This package is based on unsupervised learning.

Since it's based on the unsupervised learning, it is very flexible for new words.

But you need to train the model of it first.
"""

pip install soynlp

from konlpy.tag import Okt
tokenizer = Okt()
print(tokenizer.morphs("에이비식스 이대휘 1월 최애돌 기부 요정"))

import urllib.request
from soynlp import DoublespaceLineCorpus
from soynlp.word import WordExtractor

urllib.request.urlretrieve("https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt", filename="2016-10-20.txt")

corpus = DoublespaceLineCorpus("2016-10-20.txt")
len(corpus)

i = 0
for document in corpus:
  if len(document) > 0:
    print(document)
    i = i + 1
  if i == 3:
    break

word_extractor = WordExtractor()
word_extractor.train(corpus)
word_score_table = word_extractor.extract()

"""SOYNLP is based on cohesion probability.

Cohesion probability shows the probability of the next character based on the previous substring.

This is specifically useful to distinguish a new korean word.
"""

word_score_table["반포한"].cohesion_forward

word_score_table["반포한강"].cohesion_forward

word_score_table["반포한강공"].cohesion_forward

word_score_table["반포한강공원"].cohesion_forward

word_score_table["반포한강공원에"].cohesion_forward

"""SOYNLP is also based on branching entropy.

Branching entropy is uncertainty of the next character.

If I spell B, you never know what is the word I'm thinking of.

Now, I spell Bana, then you will see I'm thinking of Banana.

This is what branching enptropy is like.
"""

word_score_table["디스"].right_branching_entropy

word_score_table["디스플"].right_branching_entropy

word_score_table["디스플레"].right_branching_entropy

word_score_table["디스플레이"].right_branching_entropy

"""Since Korean is agglutinative language, SOYNLP's LTokenizer is very useful.

It can seperate a word into left one(stem) and right one(affix) based on the score.
"""

from soynlp.tokenizer import LTokenizer

scores = {word : score.cohesion_forward for word, score in word_score_table.items()}
l_tokenizer = LTokenizer(scores = scores)
l_tokenizer.tokenize("국제사회와 우리의 노력들로 범죄를 척결하자", flatten = False)

"""It can also make a space between words that are sticked together."""

from soynlp.tokenizer import MaxScoreTokenizer

maxscore_tokenizer = MaxScoreTokenizer(scores = scores)
maxscore_tokenizer.tokenize("국제사회와우리의노력들로범죄를척결하자")

"""###4.Cleaning repetitive letters with SOYNLP

This is as you see!

You can even do the cleaning with SOYNLP!
"""

from soynlp.normalizer import *

print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats = 2))
print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))
print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))
print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))

print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))
print(repeat_normalize('와하하하하하하하핫', num_repeats=2))
print(repeat_normalize('와하하하하하핫', num_repeats=2))

"""###5.Customized KoNLPy

You can also make your own rules for morphology!
"""

pip install customized_konlpy

from ckonlpy.tag import Twitter
twitter = Twitter()
twitter.morphs('은경이는 사무실로 갔습니다.')

twitter.add_dictionary('은경이', 'Noun')

twitter.morphs('은경이는 사무실로 갔습니다.')

"""#3.Language Model

#4. Count based word Representation

##4-2. Bag of Words
"""

from konlpy.tag import Okt

okt = Okt()

def build_bag_of_words(document):
  document = document.replace('.', '')
  tokenized_document = okt.morphs(document)

  word_to_index = {}
  bow = []

  for word in tokenized_document:
    if word not in word_to_index.keys():
      word_to_index[word] = len(word_to_index)
      bow.insert(len(word_to_index) - 1, 1)
    else:
      index = word_to_index.get(word)
      bow[index] = bow[index] + 1

  return word_to_index, bow

doc1 = "정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다."
vocab, bow = build_bag_of_words(doc1)
print("Vocabulary :", vocab)
print("Bag of words vector :", bow)

doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'

vocab, bow = build_bag_of_words(doc2)
print("Vocabulary :", vocab)
print("Bag of words vector :", bow)

doc3 = doc1 + ' ' + doc2
vocab, bow = build_bag_of_words(doc3)
print("Vocabulary :", vocab)
print("Bag of words vector :", bow)

"""Making BoW with CountVectorizer"""

from sklearn.feature_extraction.text import CountVectorizer

corpus = ['you know I want your love. because I love you.']
vector = CountVectorizer()

print("Bag of words vector :", vector.fit_transform(corpus).toarray())

print("Vocabulary :", vector.vocabulary_)

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords

text = ["Family is not an important thing. It's everything."]
vect = CountVectorizer(stop_words = ["the", "a", "an", "is", "not"])
print("Bag of words vector :", vect.fit_transform(text).toarray())
print("Vocabulary :", vect.vocabulary_)

text = ["Family is not an important thing. It's everything."]
vect = CountVectorizer(stop_words = "english")
print("Bag of words vector :", vect.fit_transform(text).toarray())
print("Vocabulary :", vect.vocabulary_)

nltk.download('stopwords')
text = ["Family is not an important thing. It's everything."]
stop_words = stopwords.words("english")
vect = CountVectorizer(stop_words = stop_words)
print("Bag of words vector :", vect.fit_transform(text).toarray())
print("Vocabulary :", vect.vocabulary_)

"""##4-4. TF-IDF(Term Frequency-Inverse Document Frequency)

Implementation with Python
"""

import pandas as pd
from math import log

docs = [
  '먹고 싶은 사과',
  '먹고 싶은 바나나',
  '길고 노란 바나나 바나나',
  '저는 과일이 좋아요'
]
vocab = list(set(w for doc in docs for w in doc.split()))
vocab.sort()

N = len(docs)

def tf(t, d):
  return d.count(t)

def idf(t):
  df = 0
  for doc in docs:
    df += t in doc
  return log(N / (df + 1))

def tfidf(t, d):
  return tf(t, d)* idf(t)

result = []

for i in range(N):
  result.append([])
  d = docs[i]
  for j in range(len(vocab)):
    t = vocab[j]
    result[-1].append(tf(t, d))

tf_ = pd.DataFrame(result, columns = vocab)
tf_

result = []
for j in range(len(vocab)):
  t = vocab[j]
  result.append(idf(t))

idf_ = pd.DataFrame(result, index = vocab, columns = ["IDF"])
idf_

result = []
for i in range(N):
  result.append([])
  d = docs[i]
  for j in range(len(vocab)):
    t = vocab[j]
    result[-1].append(tfidf(t, d))

tfdif_ = pd.DataFrame(result, columns = vocab)
tfdif_

"""Implementation with sklearn"""

from sklearn.feature_extraction.text import CountVectorizer

corpus = [
    'you know I want your love',
    'I like you',
    'what should I do ',
]

vector = CountVectorizer()

print(vector.fit_transform(corpus).toarray())

print(vector.vocabulary_)

from sklearn.feature_extraction.text import TfidfVectorizer

corpus = [
    'you know I want your love',
    'I like you',
    'what should I do ',
]

tfidfv = TfidfVectorizer().fit(corpus)
print(tfidfv.transform(corpus).toarray())
print(tfidfv.vocabulary_)

"""#5. Vector Similarity

##5-1. Cosine similarity
"""

import numpy as np
from numpy import dot
from numpy.linalg import norm

def cos_sim(A, B):
  return dot(A, B) / (norm(A) * norm(B))

doc1 = np.array([0, 1, 1, 1])
doc2 = np.array([1, 0, 1, 1])
doc3 = np.array([2, 0, 2, 2])

print('문서 1과 문서2의 유사도 :{:.2f}'.format(cos_sim(doc1, doc2)))
print('문서 1과 문서3의 유사도 :{:.2f}'.format(cos_sim(doc1, doc3)))
print('문서 2와 문서3의 유사도 :{:.2f}'.format(cos_sim(doc2, doc3)))

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

data = pd.read_csv('movies_metadata.csv', low_memory = False, error_bad_lines=False)
data.head(2)

data = data.head(20000)

print('Overview 열의 결측값의 수: ', data['overview'].isnull().sum())

data['overview'] = data['overview'].fillna(' ')

print('Overview 열의 결측값의 수: ', data['overview'].isnull().sum())

tfidf = TfidfVectorizer(stop_words = 'english')
tfidf_matrix = tfidf.fit_transform(data['overview'])
print('TF-IDF 행렬의 크기(shape) :', tfidf_matrix.shape)

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print('코사인 유사도 연산 결과 :', cosine_sim.shape)

title_to_index = dict(zip(data['title'], data.index))

idx = title_to_index['Father of the Bride Part II']
print(idx)

def get_recommendations(title, cosine_sim = cosine_sim):
  idx = title_to_index[title]
  sim_scores = list(enumerate(cosine_sim[idx]))
  sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)
  sim_scores = sim_scores[1 : 11]
  movie_indices = [idx[0] for idx in sim_scores]
  return data['title'].iloc[movie_indices]

get_recommendations('The Dark Knight Rises')

"""##5-2 Other methods for similarity"""

import numpy as np

def dist(x, y):
  return np.sqrt(np.sum((x - y) ** 2))

doc1 = np.array((2, 3, 0, 1))
doc2 = np.array((1, 2, 3, 1))
doc3 = np.array((2, 1, 2, 2))
docQ = np.array((1, 1, 0, 1))

print('문서1과 문서Q의 거리 :', dist(doc1, docQ))
print('문서2와 문서Q의 거리 :', dist(doc2, docQ))
print('문서3과 문서Q의 거리 :', dist(doc3, docQ))

doc1 = "apple banana everyone like likey watch card holder"
doc2 = "apple banana coupon passport love you"

tokenized_doc1 = doc1.split()
tokenized_doc2 = doc2.split()

print('문서1 :', tokenized_doc1)
print('문서2 :', tokenized_doc2)

union = set(tokenized_doc1).union(set(tokenized_doc2))
print('문서1과 문서2의 합집합 :', union)

intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))
print('문서1과 문서2의 교집합 :', intersection)

print('자카드 유사도 :', len(intersection) / len(union))

"""#6. Machine Learning Outline

##6-4. Practice of auto differential and linear regression

###1.Auto differential
"""

import tensorflow as tf

w = tf.Variable(2.)

def f(w):
  y = w**2
  z = 2*y + 5
  return z

with tf.GradientTape() as tape:
  z = f(w)

gradients = tape.gradient(z, [w])
print(gradients)

"""###2.Linear regression implementation with auto differential"""

w = tf.Variable(4.0)
b = tf.Variable(1.0)

@tf.function
def hypothesis(x):
  return w*x + b

x_test = [3.5, 5, 5.5, 6]
print(hypothesis(x_test).numpy())

@tf.function
def mse_loss(y_pred, y):
  return tf.reduce_mean(tf.square(y_pred - y))

x = [1, 2, 3, 4, 5, 6, 7, 8, 9]
y = [11, 22, 33, 44, 53, 66, 77, 87, 95]

optimizer = tf.optimizers.SGD(0.01)

for i in range(301):
  with tf.GradientTape() as tape:
    y_pred = hypothesis(x)
    cost = mse_loss(y_pred, y)
  gradients = tape.gradient(cost, [w, b])
  optimizer.apply_gradients(zip(gradients, [w, b]))
  if i % 10 == 0:
    print("epoch : {:3} | w value : {:5.4f} | b value : {:5.4} | cost : {:5.6f}".format(i, w.numpy(), b.numpy(), cost))

x_test = [3.5, 5, 5.5, 6]
print(hypothesis(x_test).numpy())

"""###3.Linear regression implementation with Keras"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers

x = [1, 2, 3, 4, 5, 6, 7, 8, 9]
y = [11, 22, 33, 44, 53, 66, 77, 87, 95]

model = Sequential()
model.add(Dense(1, input_dim = 1, activation = 'linear'))
sgd = optimizers.SGD(lr = 0.01)
model.compile(optimizer = sgd, loss = 'mse', metrics = ['mse'])
model.fit(x, y, epochs = 300)

plt.plot(x, model.predict(x), 'b', x, y, 'k.')

print(model.predict([9.5]))

"""##6-5. Logistic Regression

sigmoid function
"""

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
  return 1 / (1 + np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)

plt.plot(x, y, 'g')
plt.plot([0, 0], [1.0, 0.0], ':')
plt.title('Sigmoid Function')
plt.show()

def sigmoid(x):
  return 1 / (1 + np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(0.5 * x)
y2 = sigmoid(x)
y3 = sigmoid(2 * x)

plt.plot(x, y1, 'r', linestyle = '--')
plt.plot(x, y2, 'g')
plt.plot(x, y3, 'b', linestyle = '--')
plt.plot([0, 0], [1.0, 0.0], ':')
plt.title('Sigmoid Function')
plt.show()

def sigmoid(x):
  return 1 / (1 + np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(x + 0.5)
y2 = sigmoid(x + 1)
y3 = sigmoid(x + 1.5)

plt.plot(x, y1, 'r', linestyle = '--')
plt.plot(x, y2, 'g')
plt.plot(x, y3, 'b', linestyle = '--')
plt.plot([0 , 0], [1.0, 0.0], ':')
plt.title('Sigmoid Function')
plt.show()

"""##6-6. Logistic Regression Practice"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers

x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])
y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

model = Sequential()
model.add(Dense(1, input_dim = 1, activation = 'sigmoid'))

sgd = optimizers.SGD(learning_rate = 0.01)
model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])

model.fit(x, y, epochs = 200)

plt.plot(x, model.predict(x), 'b', x, y, 'k.')

print(model.predict([1, 2, 3, 4, 4.5]))
print(model.predict([11, 21, 31, 41, 500]))

"""##6-7. Multiple Input Practice

###1. Linear Regression with multiple features
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers

X = np.array([[70,85,11], [71,89,18], [50,80,20], [99,20,10], [50,10,10]])
y = np.array([73, 82 ,72, 57, 34])

model = Sequential()
model.add(Dense(1, input_dim = 3, activation = 'linear'))

sgd = optimizers.SGD(learning_rate = 0.0001)
model.compile(optimizer = sgd, loss = 'mse', metrics = ['mse'])
model.fit(X, y, epochs = 2000)

print(model.predict(X))

X_test = np.array([[20,99,10], [40,50,20]])
print(model.predict(X_test))

"""###2. Logistic Regression with multiple features"""

X = np.array([[0, 0], [0, 1], [1, 0], [0, 2], [1, 1], [2, 0]])
y = np.array([0, 0, 0, 1, 1, 1])

model = Sequential()
model.add(Dense(1, input_dim = 2, activation = 'sigmoid'))
model.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])

model.fit(X, y, epochs = 2000)

print(model.predict(X))

"""##6-8. Vector&Matrix&Tensor Calculation

###Introduction to the concepts
"""

import numpy as np

d = np.array(5)

print('Dimension of Tensor :', d.ndim)
print('Shape of Tensor :', d.shape)

d = np.array([1, 2, 3, 4])

print('Dimension of Tensor :', d.ndim)
print('Shape of Tensor :', d.shape)

d =  np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])

print('Dimension of Tensor :', d.ndim)
print('Shape of Tensor :', d.shape)

d = np.array([
            [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [10, 11, 12, 13, 14]],
            [[15, 16, 17, 18, 19], [19, 20, 21, 22, 23], [23, 24, 25, 26, 27]]
            ])

print('Dimension of Tensor :', d.ndim)
print('Shape of Tensor :', d.shape)

"""###Calculation part"""

import numpy as np

A = np.array([8, 4, 5])
B = np.array([1, 2, 3])
print('Sum of the two vectors :', A + B)
print('Difference of the two vectors :', A - B)

A = np.array([[10, 20, 30, 40], [50, 60, 70, 80]])
B = np.array([[5, 6, 7, 8],[1, 2, 3, 4]])
print('Sum of the two vectors :\n', A + B)
print('Difference of the two vectors :\n', A - B)

A = np.array([1, 2, 3])
B = np.array([4, 5, 6])
print('Dot product of the two vectors :', np.dot(A, B))

A = np.array([[1, 3], [2, 4]])
B = np.array([[5, 7], [6, 8]])
print('Multiplicaiton of the two matrices :')
print(np.matmul(A, B))

"""##6-10. SoftMax Practice"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import urllib.request
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

urllib.request.urlretrieve("https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/06.%20Machine%20Learning/dataset/Iris.csv", filename="Iris.csv")

data = pd.read_csv('Iris.csv', encoding = 'latin1')

print("No. of sample :", len(data))
print(data[:5])

print("Type of spices :", data["Species"].unique(), sep = "\n")

sns.set(style = 'ticks', color_codes = True)
g = sns.pairplot(data, hue = 'Species', palette = "husl")

sns.barplot(x = 'Species', y = 'SepalWidthCm', data = data, errorbar = None, hue = 'Species')

data['Species'].value_counts().plot(kind = 'bar')

data['Species'] = data['Species'].replace(['Iris-virginica', 'Iris-setosa', 'Iris-versicolor'], [0, 1, 2])
data['Species'].value_counts().plot(kind = 'bar')

data_X = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].values

data_y = data['Species'].values

print(data_X[:5])
print(data_y[:5])

X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, train_size = 0.8, random_state = 1)
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

print(y_train[:5])
print(y_test[:5])

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()
model.add(Dense(3, input_dim = 4, activation = 'softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
history = model.fit(X_train, y_train, epochs = 200, batch_size = 1, validation_data = (X_test, y_test))

epochs = range(1, len(history.history['accuracy']) + 1)
plt.plot(epochs, history.history['loss'])
plt.plot(epochs, history.history['val_loss'])
plt.title("model loss")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(['train', 'val'], loc = 'upper left')
plt.show()

print("\ntest accuracy: %.4f" %(model.evaluate(X_test, y_test)[1]))

"""#7. Deep Learning

##7-0. Intro

![딥러닝_개요.png](data:image/png;base64,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)

출처-https://www.lgcns.com/blog/cns-tech/ai-data/8864/

##7-1. Perceptron

As you see the picture in 7-0, we can see the relations between Machine Learning, Deep Learning, Artificial Neural Netwrok, Perceptron.

**Perceptron** < **Artificial Neural Network** < **DL** < **ML**

I think it is better to proceed the content referencing the figures in our textbook.

Keywords: neuron-perceptron, step function, bias(b value), activation function-sigmoid function

### Single-Layer Perceptron
"""

def AND_gate(x1, x2):
  w1 = 0.5
  w2 = 0.5
  b = -0.7
  result = x1 * w1 + x2 * w2 + b
  if result <= 0:
    return 0
  else:
    return 1

AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)

def NAND_gate(x1, x2):
  w1 = -0.5
  w2 = -0.5
  b = 0.7
  result = x1 * w1 + x2 * w2 + b
  if result <= 0:
    return 0
  else:
    return 1

NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)

def OR_gate(x1, x2):
  w1 = 0.6
  w2 = 0.6
  b = -0.5
  result = x1 * w1 + x2 * w2 + b
  if result <= 0:
    return 0
  else:
    return 1

OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)

"""### MultiLayer Perceptron, MLP"""

AND_gate(NAND_gate(0, 0), OR_gate(0, 0))

AND_gate(NAND_gate(0, 1), OR_gate(0, 1))

AND_gate(NAND_gate(1, 0), OR_gate(1, 0))

AND_gate(NAND_gate(1, 1), OR_gate(1, 1))

"""##7-2. Intro to Artificial Neural Network

keywords: Feed-Forward Neural Network = FFNN, Recurrent Neural Network, Fully-connected layer = FC = Dense layer, Activation Function, linear layer = projection layer, nonlinear layer
"""

import numpy as np
import matplotlib.pyplot as plt

#step_function
def step(x):
  return np.array(x > 0, dtype = int)

x = np.arange(-5.0, 5.0, 0.1)

y = step(x)
plt.title('Step Function')
plt.plot(x, y)
plt.show()

#sigmoid_function
def sigmoid(x):
  return 1 / (1 + np.exp(-x))
x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)

plt.plot(x, y)
plt.plot([0, 0], [1.0, 0.0], ':')
plt.title('Sigmoid Function')
plt.show()

#Hyperbolic tangent function
x = np.arange(-5.0, 5.0, 0.1)
y = np.tanh(x)

plt.plot(x, y)
plt.plot([0, 0], [1.0, -1.0], ':')
plt.axhline(y = 0, color = 'orange', linestyle = '--')
plt.title('Tanh Function')
plt.show()

#ReLu_function

def relu(x):
  return np.maximum(0, x)

x = np.arange(-5.0, 5.0, 0.1)
y = relu(x)

plt.plot(x, y)
plt.plot([0, 0], [5.0, 0.0], ':')
plt.title('ReLu Function')
plt.show()

#Leaky ReLu
a = 0.1
def leaky_relu(x):
  return np.maximum(a * x, x)

x = np.arange(-5.0, 5.0, 0.1)
y = leaky_relu(x)

plt.plot(x, y)
plt.plot([0, 0], [5.0, 0.0], ':')
plt.title('Leaky ReLu Function')
plt.show()

x = np.arange(-5.0, 5.0, 0.1)

y = np.exp(x) / np.sum(np.exp(x))

plt.plot(x, y)
plt.title('Softmax Function')
plt.show()

"""##7-3. Understanding Neural Network with Matrix Multiplication"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()

model.add(Dense(2, input_dim = 3, activation = 'softmax'))

model.summary()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()

model.add(Dense(8, input_dim = 4, activation = 'relu'))

model.add(Dense(8, activation = 'relu'))

model.add(Dense(3, activation = 'softmax'))

"""##7-4. The way deep learning works

.

##7-5. Back Propagation
"""



"""##7-6. How to prevent overfitting"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout, Dense

max_words = 10000
num_classes = 46

model = Sequential()
model.add(Dense(256, input_shape = (max_words,), activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation = 'softmax'))

"""##7-7. Gradient Vanishing"""

from tensorflow.keras import optimizers

Adam = optimizers.Adam(learning_rate = 0.0001, clipnorm = 1.)

"""##7-11. Text Classification with MLP"""

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer

texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']

tokenizer = Tokenizer()
tokenizer.fit_on_texts(texts)
print(tokenizer.word_index)

print(tokenizer.texts_to_matrix(texts, mode = 'count'))

print(tokenizer.texts_to_matrix(texts, mode = 'binary'))

print(tokenizer.texts_to_matrix(texts, mode = 'tfidf').round(2))

print(tokenizer.texts_to_matrix(texts, mode = 'freq').round(2))

import pandas as pd
from sklearn.datasets import fetch_20newsgroups
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical

newsdata = fetch_20newsgroups(subset = 'train')

print(newsdata.keys())

print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))

print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))
print(newsdata.target_names)

print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))

print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))

print(newsdata.data[0])

data = pd.DataFrame(newsdata.data, columns = ['email'])
data['target'] = pd.Series(newsdata.target)
data[:5]

data.info()

data.isnull().values.any()

print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))
print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))

data['target'].value_counts().plot(kind = 'bar');

print(data.groupby('target').size().reset_index(name = 'count'))

newsdata_test = fetch_20newsgroups(subset = 'test', shuffle = True)
train_email = data['email']
train_label = data['target']
test_email = newsdata_test.data
test_label = newsdata_test.target

vocab_size = 10000
num_classes = 20

def prepare_data(train_data, test_data, mode):
  tokenizer = Tokenizer(num_words = vocab_size)
  tokenizer.fit_on_texts(train_data)
  X_train = tokenizer.texts_to_matrix(train_data, mode = mode)
  X_test = tokenizer.texts_to_matrix(test_data, mode = mode)
  return X_train, X_test, tokenizer.index_word

X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary')
y_train = to_categorical(train_label, num_classes)
y_test = to_categorical(test_label, num_classes)

print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))
print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))
print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))
print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))

print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))
print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

def fit_and_evaluate(X_train, y_train, X_test, y_test):
  model = Sequential()
  model.add(Dense(256, input_shape = (vocab_size,), activation = 'relu'))
  model.add(Dropout(0.5))
  model.add(Dense(128, activation = 'relu'))
  model.add(Dropout(0.5))
  model.add(Dense(num_classes, activation = 'softmax'))

  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
  model.fit(X_train, y_train, batch_size = 128, epochs = 5, verbose = 1, validation_split = 0.1)
  score = model.evaluate(X_test, y_test, batch_size = 128, verbose = 0)
  return score[1]

modes = ['binary', 'count', 'tfidf', 'freq']

for mode in modes:
  X_train, X_test, _ = prepare_data(train_email, test_email, mode)
  score = fit_and_evaluate(X_train, y_train, X_test, y_test)
  print(mode+' 모드의 테스트 정확도:', score)

"""##7-12. Neural Network Language Model, NNLM

![images.jpeg](data:image/jpeg;base64,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)

#8. Recurrent Neural Network

##8-1. Recurrent Neural Network

###1. Recurrent Neural Network
"""



"""###2. Implementation of RNN with Keras"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN

model = Sequential()
model.add(SimpleRNN(3, input_shape = (2, 10)))
model.summary()

model = Sequential()
model.add(SimpleRNN(3, batch_input_shape = (8, 2, 10)))
model.summary()

model = Sequential()
model.add(SimpleRNN(3, batch_input_shape = (8, 2, 10), return_sequences = True))
model.summary()

"""###3. RNN implementation with Python"""

import numpy as np

timesteps = 10
input_dim = 4
hidden_units = 8

inputs = np.random.random((timesteps, input_dim))

hidden_state_t = np.zeros((hidden_units, ))

print("초기 은닉 상태 :", hidden_state_t)

Wx = np.random.random((hidden_units, input_dim))
Wh = np.random.random((hidden_units, hidden_units))
b = np.random.random((hidden_units, ))

print("가중치 Wx의 크기(shape) :", np.shape(Wx))
print("가중치 Wb의 크기(shape) :", np.shape(Wh))
print("편향의 크기(shape) :", np.shape(b))

total_hidden_states = []

for input_t in inputs:
  output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b)
  total_hidden_states.append(list(output_t))
  hidden_state_t = output_t

total_hidden_states = np.stack(total_hidden_states, axis = 0)

print("모든 시점의 은닉 상태 :")
print(total_hidden_states)

"""The result above shows that the values of hidden_state_t approached to 1.

It is because the weighted hidden state values in the previous step are added to the current step's input of activation function.

###4. Deep Recurrent Neural Network
"""

model = Sequential()
model.add(SimpleRNN(hidden_units, input_length = 10, input_dim = 5, return_sequences= True))
model.add(SimpleRNN(hidden_units, return_sequences = True))

"""###5. Bidirection Recurrent Neural Network"""

from tensorflow.keras.layers import Bidirectional

timesteps = 10
input_dim = 5

model = Sequential()
model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences = True), input_shape = (timesteps, input_dim)))

model = Sequential()
model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))
model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))
model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))
model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))

"""##8-2. Long Short-Term Memory, LSTM

###1. Limitation of Vanilla RNN

The problem of Long-Term Dependencies

###2. Inside of Vanilla RNN

.

###3. LSTM

.

##8-3. Gated Recurrent Unit, GRU

###1. GRU

.

###2. GRU in Keras
"""

#model.add(GRU(hidden_size, input_shape = (timesteps, input_dim)))

"""##8-4. SimpleRNN and LSTM in Keras

###1. Randering Random Input
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional

train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]
print(np.shape(train_X))

train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]
train_X = np.array(train_X, dtype=np.float32)
print(train_X.shape)

"""###2. SimpleRNN"""

rnn = SimpleRNN(3)
hidden_state = rnn(train_X)

print("Hidden state : {}, shape : {}".format(hidden_state, hidden_state.shape))

rnn = SimpleRNN(3, return_sequences = True)
hidden_states = rnn(train_X)

print("Hidden states : {}, shape : {}".format(hidden_states, hidden_states.shape))

rnn = SimpleRNN(3, return_sequences = True, return_state = True)
hidden_states, last_state = rnn(train_X)

print("Hidden states : {}, shape : {}".format(hidden_states, hidden_states.shape))
print("Last hidden state : {}, shape : {}".format(last_state, last_state.shape))

rnn = SimpleRNN(3, return_sequences=False, return_state=True)
hidden_state, last_state = rnn(train_X)

print('Hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))
print('Last hidden state : {}, shape: {}'.format(last_state, last_state.shape))

"""###3. LSTM"""

lstm = LSTM(3, return_sequences = False, return_state = True)
hidden_state, last_state, last_cell_state = lstm(train_X)

print("Hidden state : {}, shape : {}".format(hidden_state, hidden_state.shape))
print("Last hidden state : {}, shape : {}".format(last_state, last_state.shape))
print("Last cell state : {}, shape : {}".format(last_cell_state, last_cell_state.shape))

lstm = LSTM(3, return_sequences = True, return_state = True)
hidden_state, last_state, last_cell_state = lstm(train_X)

print("Hidden state : {}, shape : {}".format(hidden_state, hidden_state.shape))
print("Last hidden state : {}, shape : {}".format(last_state, last_state.shape))
print("Last cell state : {}, shape : {}".format(last_cell_state, last_cell_state.shape))

"""###4. Bidirectional LSTM"""

k_init = tf.keras.initializers.Constant(value = 0.1)
b_init = tf.keras.initializers.Constant(value = 0)
r_init = tf.keras.initializers.Constant(value = 0.1)

bilstm = Bidirectional(LSTM(3, return_sequences = False, return_state = True, kernel_initializer = k_init, bias_initializer = b_init, recurrent_initializer = r_init))
hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)

print("Hidden states : {}, shape : {}".format(hidden_states, hidden_states.shape))
print("Forward state : {}, shape : {}".format(forward_h, forward_h.shape))
print("Backward state : {}, shape : {}".format(backward_h, backward_h.shape))

bilstm = Bidirectional(LSTM(3, return_sequences = True, return_state = True, kernel_initializer = k_init, bias_initializer = b_init, recurrent_initializer = r_init))
hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)

print("Hidden states : {}, shape : {}".format(hidden_states, hidden_states.shape))
print("Forward state : {}, shape : {}".format(forward_h, forward_h.shape))
print("Backward state : {}, shape : {}".format(backward_h, backward_h.shape))

"""##8-5. RNN Language Model

###pass

##8-6.Text Generation using RNN

###1. Text Generation with RNN
"""

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

text = """경마장에 있는 말이 뛰고 있다\n
그의 말이 법이다\n
가는 말이 고와야 오는 말이 곱다\n"""

tokenizer = Tokenizer()
tokenizer.fit_on_texts([text])
vocab_size = len(tokenizer.word_index) + 1
print("단어 집합의 크기 : %d" % vocab_size)

print(tokenizer.word_index)

sequences = list()
for line in text.split('\n'):
  encoded = tokenizer.texts_to_sequences([line])[0]
  for i in range(1, len(encoded)):
    sequence = encoded[: i + 1]
    sequences.append(sequence)
print("학습에 사용할 샘플의 개수 : %d" % len(sequences) )

print(sequences)

max_len = max(len(l) for l in sequences)
print("샘플의 최대 길이 : {}".format(max_len))

sequences = pad_sequences(sequences, maxlen = max_len, padding = 'pre')

print(sequences)

sequences = np.array(sequences)
X = sequences[: , : -1]
y = sequences[: , -1]

print(X)

print(y)

y = to_categorical(y, num_classes = vocab_size)

print(y)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Dense, SimpleRNN

embedding_dim = 10
hidden_units = 32

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim))
model.add(SimpleRNN(hidden_units))
model.add(Dense(vocab_size, activation = 'softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model.fit(X, y, epochs = 200, verbose = 2)

def sentence_generation(model, tokenizer, current_word, n):
  init_word = current_word
  sentence = ''
  for _ in range(n):
    encoded = tokenizer.texts_to_sequences([current_word])[0]
    encoded = pad_sequences([encoded], maxlen = 5, padding = 'pre')
    result = model.predict(encoded, verbose = 0)
    result = np.argmax(result, axis = 1)
    for word, index in tokenizer.word_index.items():
      if index == result:
        break
    current_word = current_word + ' ' + word
    sentence = sentence + ' ' + word
  sentence = init_word + sentence
  return sentence

print(sentence_generation(model, tokenizer, '경마장에', 4))

print(sentence_generation(model, tokenizer, '그의', 2))

print(sentence_generation(model, tokenizer, '가는', 5))

"""###2. Text Generation with LSTM"""

import pandas as pd
import numpy as np
from string import punctuation

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

df = pd.read_csv('ArticlesApril2018.csv')
df.head()

print('열의 개수:', len(df.columns))
print(df.columns)

print(df['headline'].isnull().values.any())

headline = []
headline.extend(list(df.headline.values))
headline[:5]

print('총 샘플의 개수 : {}'.format(len(headline)))

headline = [word for word in headline if word != "Unknown"]
print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))

headline[:5]

def repreprocessing(raw_sentence):
  preprocessed_sentence = raw_sentence.encode("utf8").decode("ascii", 'ignore')
  return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()
preprocessed_headline = [repreprocessing(x) for x in headline]
preprocessed_headline[:5]

tokenizer = Tokenizer()
tokenizer.fit_on_texts(preprocessed_headline)
vocab_size = len(tokenizer.word_index) + 1
print('단어 집합의 크기 : %d' % vocab_size)

sequences = list()

for sentence in preprocessed_headline:
  encoded = tokenizer.texts_to_sequences([sentence])[0]
  for i in range(1, len(encoded)):
    sequence = encoded[:i + 1]
    sequences.append(sequence)
sequences[:11]

index_to_word = {}
for key, value in tokenizer.word_index.items():
  index_to_word[value] = key
print("빈도수 상위 582번 단어 : {}".format(index_to_word[582]))

max_len = max(len(l) for l in sequences)
print("샘플의 최대 길이 : {}".format(max_len))

sequences = pad_sequences(sequences, maxlen = max_len, padding = 'pre')
print(sequences[:3])

sequences = np.array(sequences)
X = sequences[:, :-1]
y = sequences[:, -1]

print(X[:3])

print(y[:3])

y = to_categorical(y, num_classes = vocab_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Dense, LSTM

embedding_dim = 10
hidden_units = 128

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim))
model.add(LSTM(hidden_units))
model.add(Dense(vocab_size, activation = 'softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model.fit(X, y, epochs = 200, verbose = 2)

def sentence_generation(model, tokenizer, current_word, n):
  init_word = current_word
  sentence = ''
  for _ in range(n):
    encoded = tokenizer.texts_to_sequences([current_word])[0]
    encoded = pad_sequences([encoded], maxlen = max_len - 1, padding = 'pre')
    result = model.predict(encoded, verbose = 0)
    result = np.argmax(result, axis = 1)
    for word, index in tokenizer.word_index.items():
      if index == result:
        break
    current_word = current_word + ' ' + word
    sentence = sentence + ' ' + word
  sentence = init_word + sentence
  return sentence

print(sentence_generation(model, tokenizer, 'i', 10))

print(sentence_generation(model, tokenizer, 'how', 10))

"""##8-7.Char RNN

###1.Character Unit RNNLM(Many-to-Many)
"""

import numpy as np
import urllib.request
from tensorflow.keras.utils import to_categorical

urllib.request.urlretrieve("http://www.gutenberg.org/files/11/11-0.txt", filename = "11-0.txt")

f = open('11-0.txt', 'rb')
sentences = []
for sentence in f:
  sentence = sentence.strip()
  sentence = sentence.lower()
  sentence = sentence.decode('ascii', 'ignore')
  if len(sentence) > 0:
    sentences.append(sentence)
f.close()

sentences[:5]

total_data = ' '.join(sentences)
print("문자열의 길이 또는 총 문자의 개수 : %d" %len(total_data))

print(total_data[:200])

char_vocab = sorted(list(set(total_data)))
vocab_size = len(char_vocab)
print("문자 집합의 크기 : {}".format(vocab_size))

char_to_index = dict((char, index) for index, char in enumerate(char_vocab))
print('문자 집합 :', char_to_index)

index_to_char = {}
for key, value in char_to_index.items():
  index_to_char[value] = key

train_X = 'appl'
train_y = 'pple'

seq_length = 60
n_samples = int(np.floor((len(total_data) - 1) / seq_length))
print("샘플의 수 : {}".format(n_samples))

train_X = []
train_y = []
for i in range(n_samples):
  X_sample = total_data[i * seq_length: (i + 1) * seq_length]
  X_encoded = [char_to_index[c] for c in X_sample]
  train_X.append(X_encoded)
  y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]
  y_encoded = [char_to_index[c] for c in y_sample]
  train_y.append(y_encoded)

print("X 데이터의 첫번째 샘플 :", train_X[0])
print("y 데이터의 첫번째 샘플 :", train_y[0])
print('-' * 50)
print('X 데이터의 첫번째 샘플 디코딩 :', [index_to_char[i] for i in train_X[0]])
print('y 데이터의 첫번째 샘플 디코딩 :', [index_to_char[i] for i in train_y[0]])

print(train_X[1])

print(train_y[1])

train_X = to_categorical(train_X)
train_y = to_categorical(train_y)

print('train_X의 크기 (shape) : {}'.format(train_X.shape))
print('train_y의 크기 (shape) : {}'.format(train_y.shape))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, TimeDistributed

hidden_units = 256

model = Sequential()
model.add(LSTM(hidden_units, input_shape = (None, train_X.shape[2]), return_sequences = True))
model.add(LSTM(hidden_units, return_sequences = True))
model.add(TimeDistributed(Dense(vocab_size, activation = 'softmax')))
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model.fit(train_X, train_y, epochs = 80, verbose = 2)

def sentence_generation(model, length):
  ix = [np.random.randint(vocab_size)]
  y_char = [index_to_char[ix[-1]]]
  print(ix[-1], '번 문자', y_char[-1], '로 예측을 시작!')
  x = np.zeros((1, length, vocab_size))
  for i in range(length):
    x[0][i][ix[-1]] = 1
    print(index_to_char[ix[-1]], end = "")
    ix = np.argmax(model.predict(train_X[:, :i + 1, :])[0], 1)
    y_char.append(index_to_char[ix[-1]])
  return ('').join(y_char)

result = sentence_generation(model, 100)
print(result)

"""###2. Many-to-One"""

import numpy as np
from tensorflow.keras.utils import to_categorical

raw_text = '''
I get on with life as a programmer,
I like to contemplate beer.
But when I start to daydream,
My mind turns straight to wine.

Do I love wine more than beer?

I like to use words about beer.
But when I stop my talking,
My mind turns straight to wine.

I hate bugs and errors.
But I just think back to wine,
And I'm happy once again.

I like to hang out with programming and deep learning.
But when left alone,
My mind turns straight to wine.
'''

tokens = raw_text.split()
raw_text = ' '.join(tokens)
print(raw_text)

char_vocab = sorted(list(set(raw_text)))
vocab_size = len(char_vocab)
print('문자 집합 :', char_vocab)
print('문자 집합의 크기 : {}'.format(vocab_size))

char_to_index = dict((char, index) for index, char in enumerate(char_vocab))
print(char_to_index)

length = 11
sequences = []
for i in range(length, len(raw_text)):
  seq = raw_text[i - length : i]
  sequences.append(seq)
print('총 훈련 샘플의 수 : %d' % len(sequences))

sequences[:10]

encoded_sequences = []
for sequence in sequences:
  encoded_sequence = [char_to_index[char] for char in sequence]
  encoded_sequences.append(encoded_sequence)

encoded_sequences[:5]

encoded_sequences = np.array(encoded_sequences)
X_data = encoded_sequences[:, :-1]
y_data = encoded_sequences[:, -1]

print(X_data[:5])
print(y_data[:5])

X_data_one_hot = [to_categorical(encoded, num_classes = vocab_size) for encoded in X_data]
X_data_one_hot = np.array(X_data_one_hot)
y_data_one_hot = to_categorical(y_data, num_classes = vocab_size)

print(X_data_one_hot.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.preprocessing.sequence import pad_sequences

hidden_units = 64

model = Sequential()
model.add(LSTM(hidden_units, input_shape = (X_data_one_hot.shape[1], X_data_one_hot.shape[2])))
model.add(Dense(vocab_size, activation = 'softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model.fit(X_data_one_hot, y_data_one_hot, epochs = 100, verbose = 2)

def sentence_generation(model, char_to_index, seq_length, seed_text, n):
  init_text = seed_text
  sentence = ''
  for _ in range(n):
    encoded = [char_to_index[char] for char in seed_text]
    encoded = pad_sequences([encoded], maxlen = seq_length, padding = 'pre')
    encoded = to_categorical(encoded, num_classes = len(char_to_index))
    result = model.predict(encoded, verbose = 0)
    result = np.argmax(result, axis = 1)
    for char, index in char_to_index.items():
      if index == result:
        break
    seed_text = seed_text + char
    sentence = sentence + char
  sentence = init_text + sentence
  return sentence

print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))

"""#9.Word Embedding

##9-1.Word Embedding

###1.Sparse Representation

.

###2.Dense Representation

Dense vector

###3.Word Embedding

###.

##9-2. Word2Vec

###1.Parse Representation

Distributed Representation

###2.Distributed Representation

.

###3.CBOW(Continuous Bag of Words)

.

###4.Skip-gram

.

###5.NNLM  vs Word2Vec

.

##9-3.Word2Vec in Korean and English

###1.Word2VEc in English
"""

import re
import urllib.request
import zipfile
from lxml import etree
from nltk.tokenize import word_tokenize, sent_tokenize

# 데이터 다운로드
urllib.request.urlretrieve("https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml", filename="ted_en-20160408.xml")

import nltk
nltk.download('punkt')
targetXML = open('ted_en-20160408.xml', 'r', encoding = 'UTF8')
target_text = etree.parse(targetXML)
parse_text = '\n'.join(target_text.xpath('//content/text()'))
content_text = re.sub(r'\([^)]*\)', '', parse_text)
sent_text = sent_tokenize(content_text)
normalized_text = []
for string in sent_text:
  tokens = re.sub(r"[^a-z0-9]+", " ", string.lower())
  normalized_text.append(tokens)
result = [word_tokenize(sentence) for sentence in normalized_text]

print('총 샘플의 개수 : {}'.format(len(result)))

for line in result[:3]:
  print(line)

from gensim.models import Word2Vec
from gensim.models import KeyedVectors

model = Word2Vec(sentences = result, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)

model_result = model.wv.most_similar("man")
print(model_result)

model.wv.save_word2vec_format('eng_w2v')
loaded_model = KeyedVectors.load_word2vec_format("eng_w2v")

model_result = loaded_model.most_similar("man")
print(model_result)

"""###2. Word2Vec in Korean (with Naver Movie Comments)"""

import pandas as pd
import matplotlib.pyplot as plt
import urllib.request
from gensim.models.word2vec import Word2Vec
from konlpy.tag import Okt

urllib.request.urlretrieve("https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt", filename="ratings.txt")

train_data = pd.read_table('ratings.txt')

train_data[:5]

print(len(train_data))

print(train_data.isnull().values.any())

train_data = train_data.dropna(how = 'any')
print(train_data.isnull().values.any())

print(len(train_data))

train_data['document'] = train_data['document'].str.replace("[^ㄱ-하-ㅣ가-힣]","")

train_data[:5]

#! pip install tqdm
from tqdm import tqdm
stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']

okt = Okt()

tokenized_data = []
for sentence in tqdm(train_data['document']):
  tokenized_sentence = okt.morphs(sentence, stem = True)
  stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]
  tokenized_data.append(stopwords_removed_sentence)

print('리뷰의 최대 길이 :', max(len(review) for review in tokenized_data))
print('리뷰의 평균 길이 :', sum(map(len, tokenized_data)) / len(tokenized_data))
plt.hist([len(review) for review in tokenized_data], bins = 50)
plt.xlabel('length of samples')
plt.ylabel('number of samples')
plt.show()

from gensim.models import Word2Vec

model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)

model.wv.vectors.shape

print(model.wv.most_similar("최민식"))

print(model.wv.most_similar("히어로"))

"""###3.Pretrained Word2Vec"""

#Link expired
#import gensim
#import urllib.request
# 구글의 사전 훈련된 Word2Vec 모델을 로드.
#urllib.request.urlretrieve("https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz", filename="GoogleNews-vectors-negative300.bin.gz")
#word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)

"""From Chapter 9-2, I will write on another ipynb file."""
